# Kimberly-Clark Hackathon: Optimal Paper Mill Location Analysis

## Overview

This project was developed as part of the Kimberly-Clark Hackathon to address a real-world logistics challenge: **identifying optimal locations for new Kimberly-Clark paper mills** across the United States. The goal was to engineer a data-driven logistics optimization solution that minimizes transportation costs for major metropolitan markets, while factoring in sustainability, employment, and ethical considerations.

---

## Problem Statement

Kimberly-Clark sought to:
- **Minimize transportation costs** for servicing key metro areas.
- **Incorporate sustainability and employment factors** into location decisions.
- **Ensure long-term ethical and business impact**.

---

## Solution Highlights

- **Data Pipeline Automation**  
  Designed and implemented ETL pipelines in Python to extract, clean, and aggregate open-source datasets, automating manual data collection.

- **Cloud-based Analytics Architecture**  
  Architected scalable workflows using Google BigQuery for data storage/processing, and developed regression models to simulate logistics scenarios across 20+ metropolitan regions.

- **Interactive Dashboards**  
  Built Tableau dashboards to visualize mill locations, transportation routes, and cost scenarios for stakeholder insights and decision-making.

- **Team & Stakeholder Collaboration**  
  Translated business objectives into technical requirements by working closely with team members and stakeholders, ensuring alignment with both logistics and broader business needs.

---

## Repository Structure

```
Kimberly_Clark_Hackathon/
├── Dashboards/          # Tableau dashboard files & visualizations
├── Data/                # Raw and processed datasets
├── Presentation/        # Final presentation and supporting documents
├── .git/                # Git version control files
├── .gitattributes
└── README.md            # Project overview and instructions
```

---

## How to Use This Repository

1. **Clone the repository**  
   ```bash
   git clone https://github.com/yourusername/Kimberly_Clark_Hackathon.git
   ```

2. **Data Processing**  
   - Scripts and Jupyter notebooks (see `/Data` folder) extract and preprocess open-source data relevant to logistics and sustainability.
   - ETL pipelines automate data extraction and aggregation.

3. **Analytics & Modeling**  
   - Python scripts (in `/Data` or `/Presentation`) model logistics scenarios using regression and cost-minimization techniques.

4. **Dashboards**  
   - Open Tableau workbooks in the `/Dashboards` folder to interactively explore results and insights.

5. **Presentation**  
   - Final results and business recommendations are included in the `/Presentation` folder.

---

## Technologies Used

- **Python** (ETL pipelines, data cleaning, modeling)
- **Google BigQuery** (cloud analytics, scalable storage)
- **Tableau** (interactive dashboards)
- **Jupyter Notebook**
- **Git** (version control)

---

## Developed by

- Tanmay Itkelwar
- Kaushil Mangloria
- Robin Shukla
- Jahnani Sivakumar

---

## License

This project is for educational and demonstration purposes only.

---

*For questions or collaboration, please open an issue or contact the repository owner.*
